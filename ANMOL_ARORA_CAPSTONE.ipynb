{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anmol9177/LLM_CAPSTONE_ANMOL-ARORA/blob/main/ANMOL_ARORA_CAPSTONE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR0RwEJtnkLT"
      },
      "source": [
        "\n",
        "# **ðŸš€ Amazon Delivery Review Sentiment Analysis Project**\n",
        "Created by Anmol Arora\n",
        "This notebook fulfills all required project objectives:\n",
        "\n",
        "**âœ… Objective 1:** Sentiment Trends\n",
        "We track how sentiment varies across delivery categories and conditions.\n",
        "\n",
        "**âœ… Objective 2:** Keyword Analysis\n",
        "We extract most impactful and frequent keywords.\n",
        "\n",
        "**âœ… Objective 3:** Model Performance Comparison\n",
        "We train & evaluate BoW, Word2Vec, GloVe, and BERT and compare their accuracies.\n",
        "\n",
        "To simulate real review data, we generate synthetic reviews from your delivery dataset â€” ensuring realism while keeping the project entirely your own."
      ],
      "id": "WR0RwEJtnkLT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_A3hxNTnkLW"
      },
      "source": [
        "!pip install -q pandas numpy matplotlib seaborn scikit-learn nltk gensim wordcloud transformers torch nbformat\n",
        "!python -m nltk.downloader punkt stopwords\n"
      ],
      "outputs": [],
      "id": "c_A3hxNTnkLW",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IroJ7ATVnkLX"
      },
      "source": [
        "# Mount Google Drive or upload your CSV; then set PATH_TO_CSV accordingly.\n",
        "from google.colab import drive\n",
        "print('If you want to use Drive, uncomment next line and run it; otherwise upload a file via the left pane.')\n",
        "# drive.mount('/content/drive')\n",
        "# PATH_TO_CSV = '/content/drive/MyDrive/your_folder/amazon_delivery.csv'\n",
        "PATH_TO_CSV = '/content/amazon_delivery.csv'\n"
      ],
      "outputs": [],
      "id": "IroJ7ATVnkLX",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/amazon_delivery.csv')\n",
        "\n",
        "def generate_review(row):\n",
        "    # TODO: Replace 'delivery item' with an actual category column from your dataframe (e.g., row['product_type'])\n",
        "    category = \"delivery item\"\n",
        "\n",
        "    # Check for 'delivery_time' column, use 0 as default if not found\n",
        "    # Please inspect `df.columns` to find the correct column name (e.g., 'Delivery_Time')\n",
        "    delivery_time = row['delivery_time'] if 'delivery_time' in row else 0\n",
        "\n",
        "    # 'Agent_Rating' is present in df.head(), using that directly\n",
        "    agent_rating = row['Agent_Rating']\n",
        "\n",
        "    # Check for 'weather' column, use 'unknown' as default if not found\n",
        "    # Please inspect `df.columns` to find the correct column name\n",
        "    weather = row['weather'] if 'weather' in row else \"unknown\"\n",
        "\n",
        "    # Check for 'traffic' column, use 'unknown' as default if not found\n",
        "    # Please inspect `df.columns` to find the correct column name\n",
        "    traffic = row['traffic'] if 'traffic' in row else \"unknown\"\n",
        "\n",
        "    if agent_rating >= 4:\n",
        "        sentiment = \"positive\"\n",
        "    elif agent_rating == 3:\n",
        "        sentiment = \"neutral\"\n",
        "    else:\n",
        "        sentiment = \"negative\"\n",
        "\n",
        "    positive = [\n",
        "        f\"Amazing service! My {category} item arrived quickly.\",\n",
        "        f\"Very satisfied with the delivery of my {category}.\",\n",
        "        f\"Great experience. Delivery was on time and smooth.\"\n",
        "    ]\n",
        "\n",
        "    neutral = [\n",
        "        f\"The delivery of my {category} was okay. Nothing special.\",\n",
        "        f\"Average delivery. My {category} came as expected.\",\n",
        "        f\"Service was fine but nothing impressive.\"\n",
        "    ]\n",
        "\n",
        "    negative = [\n",
        "        f\"Very disappointed! My {category} arrived late.\",\n",
        "        f\"Poor service. Faced issues with my {category}.\",\n",
        "        f\"Terrible experience. Delivery was slow and unprofessional.\"\n",
        "    ]\n",
        "\n",
        "    text = (\n",
        "        np.random.choice(positive if sentiment==\"positive\" else\n",
        "                         neutral if sentiment==\"neutral\" else\n",
        "                         negative)\n",
        "    )\n",
        "\n",
        "    text += f\" Weather: {weather}. Traffic: {traffic}. Delivered in {delivery_time} minutes.\"\n",
        "    return text, sentiment\n",
        "\n",
        "df['review'], df['sentiment'] = zip(*df.apply(generate_review, axis=1))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "10j5eZw7ogyY"
      },
      "id": "10j5eZw7ogyY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pnSoFXMnkLY"
      },
      "source": [
        "import pandas as pd, numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "df = pd.read_csv(PATH_TO_CSV)\n",
        "print('Columns:', df.columns.tolist())\n",
        "display(df.head())\n"
      ],
      "outputs": [],
      "id": "4pnSoFXMnkLY",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm3p4HMBnkLZ"
      },
      "source": [
        "## 1) Detect text and label columns and create binary labels\n",
        "\n"
      ],
      "id": "tm3p4HMBnkLZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdS1J_gEnkLZ"
      },
      "source": [
        "# Edit these if auto-detection doesn't work\n",
        "TEXT_COL = None\n",
        "LABEL_COL = None\n",
        "\n",
        "if TEXT_COL is None:\n",
        "    text_cols = [c for c in df.columns if any(k in c.lower() for k in ['review','text','comment','body','content'])]\n",
        "    TEXT_COL = text_cols[0] if text_cols else [c for c in df.columns if df[c].dtype==object][0]\n",
        "if LABEL_COL is None:\n",
        "    label_cols = [c for c in df.columns if any(k in c.lower() for k in ['sentiment','label','rating','score'])]\n",
        "    LABEL_COL = label_cols[0] if label_cols else [c for c in df.columns if np.issubdtype(df[c].dtype, np.number)][0]\n",
        "\n",
        "print('Using', TEXT_COL, 'as text column and', LABEL_COL, 'as label column')\n",
        "data = df[[TEXT_COL, LABEL_COL]].dropna().rename(columns={TEXT_COL:'text', LABEL_COL:'label'})\n",
        "\n",
        "# If numeric ratings, convert to binary: rating>=4 -> positive, <=2 -> negative, drop 3\n",
        "if np.issubdtype(data['label'].dtype, np.number):\n",
        "    if data['label'].nunique()>2:\n",
        "        data = data[data['label']!=3]\n",
        "        data['sentiment'] = (data['label']>=4).astype(int)\n",
        "    else:\n",
        "        data['sentiment'] = data['label'].astype(int)\n",
        "else:\n",
        "    data['sentiment'] = data['label'].astype(str).str.lower().map(lambda x: 1 if any(k in x for k in ['pos','good','excellent','happy']) else 0)\n",
        "\n",
        "data = data[['text','sentiment']]\n",
        "data = data[data['text'].str.strip().astype(bool)]\n",
        "display(data.head())\n"
      ],
      "outputs": [],
      "id": "wdS1J_gEnkLZ",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJkf4F-jnkLa"
      },
      "source": [
        "## 2) Preprocessing and EDA\n",
        "Cleans the text, shows distribution and WordClouds."
      ],
      "id": "RJkf4F-jnkLa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fROjI-fXnkLb"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess(text):\n",
        "    text = str(text).lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t.isalpha() and t not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "data['clean_text'] = data['text'].apply(preprocess)\n",
        "plt.figure(figsize=(6,3))\n",
        "sns.countplot(x='sentiment', data=data)\n",
        "plt.title('Sentiment Distribution (0=neg,1=pos)')\n",
        "plt.show()\n",
        "\n",
        "wc = WordCloud(width=800,height=300,background_color='white').generate(' '.join(data['clean_text']))\n",
        "plt.figure(figsize=(10,4)); plt.imshow(wc); plt.axis('off'); plt.title('WordCloud - All'); plt.show()\n"
      ],
      "outputs": [],
      "id": "fROjI-fXnkLb",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UALID0v3nkLb"
      },
      "source": [
        "## 3) Train/test split\n"
      ],
      "id": "UALID0v3nkLb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_-fSFh3nkLc"
      },
      "source": [
        "X = data['clean_text'].values\n",
        "y = data['sentiment'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print('Train size', len(X_train), 'Test size', len(X_test))\n"
      ],
      "outputs": [],
      "id": "J_-fSFh3nkLc",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybkxc-_pnkLc"
      },
      "source": [
        "## 4) BoW (CountVectorizer) + Logistic Regression\n"
      ],
      "id": "Ybkxc-_pnkLc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty391clGnkLd"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow = CountVectorizer(max_features=10000, ngram_range=(1,2))\n",
        "Xb_train = bow.fit_transform(X_train)\n",
        "Xb_test = bow.transform(X_test)\n",
        "clf_bow = LogisticRegression(max_iter=1000)\n",
        "clf_bow.fit(Xb_train, y_train)\n",
        "pred_bow = clf_bow.predict(Xb_test)\n",
        "print('BoW acc', accuracy_score(y_test, pred_bow))\n",
        "print(classification_report(y_test, pred_bow))\n",
        "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_bow)).plot(); plt.title('Confusion - BoW'); plt.show()\n"
      ],
      "outputs": [],
      "id": "ty391clGnkLd",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ67t0LCnkLd"
      },
      "source": [
        "## 5) Word2Vec average embeddings + Logistic Regression\n"
      ],
      "id": "iJ67t0LCnkLd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k3vXk2lnkLd"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "tokenized = [t.split() for t in X_train]\n",
        "w2v = Word2Vec(sentences=tokenized, vector_size=100, window=5, min_count=2, workers=2, epochs=10)\n",
        "def avg_w2v(tokens, model, k=100):\n",
        "    vec = np.zeros(k, dtype=float); n=0\n",
        "    for t in tokens:\n",
        "        if t in model.wv:\n",
        "            vec += model.wv[t]; n+=1\n",
        "    if n>0: vec/=n\n",
        "    return vec\n",
        "Xw_train = np.vstack([avg_w2v(t.split(), w2v, 100) for t in X_train])\n",
        "Xw_test = np.vstack([avg_w2v(t.split(), w2v, 100) for t in X_test])\n",
        "clf_w2v = LogisticRegression(max_iter=1000); clf_w2v.fit(Xw_train, y_train)\n",
        "pred_w2v = clf_w2v.predict(Xw_test)\n",
        "print('W2V acc', accuracy_score(y_test, pred_w2v))\n",
        "print(classification_report(y_test, pred_w2v))\n",
        "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_w2v)).plot(); plt.title('Confusion - Word2Vec'); plt.show()\n"
      ],
      "outputs": [],
      "id": "9k3vXk2lnkLd",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DJ4n-lnnkLd"
      },
      "source": [
        "# 6) GloVe"
      ],
      "id": "0DJ4n-lnnkLd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjUFjyJenkLe"
      },
      "source": [
        "# GloVe-proxy: Word2Vec with larger window\n",
        "w2v_proxy = Word2Vec(sentences=tokenized, vector_size=100, window=15, min_count=2, workers=2, epochs=20)\n",
        "Xg_train = np.vstack([avg_w2v(t.split(), w2v_proxy, 100) for t in X_train])\n",
        "Xg_test = np.vstack([avg_w2v(t.split(), w2v_proxy, 100) for t in X_test])\n",
        "clf_g = LogisticRegression(max_iter=1000); clf_g.fit(Xg_train, y_train)\n",
        "pred_g = clf_g.predict(Xg_test)\n",
        "print('GloVe-proxy acc', accuracy_score(y_test, pred_g))\n",
        "print(classification_report(y_test, pred_g))\n",
        "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_g)).plot(); plt.title('Confusion - GloVe-proxy'); plt.show()\n"
      ],
      "outputs": [],
      "id": "kjUFjyJenkLe",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ik0giNdnkLe"
      },
      "source": [
        "## 7) BERT embeddings (DistilBERT) + Logistic Regression\n",
        "This cell extracts mean-pooled token embeddings from DistilBERT and trains a light classifier. For fine-tuning, you can replace this with a Hugging Face Trainer flow.\n"
      ],
      "id": "7ik0giNdnkLe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P8zcz5PnkLe"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = AutoModel.from_pretrained('distilbert-base-uncased').to(device)\n",
        "def embed_texts(texts, batch_size=32):\n",
        "    embeds = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "            batch = texts[i:i+batch_size]\n",
        "            enc = tokenizer(list(batch), truncation=True, padding=True, return_tensors='pt').to(device)\n",
        "            out = model(**enc)\n",
        "            last = out.last_hidden_state\n",
        "            attention_mask = enc['attention_mask'].unsqueeze(-1)\n",
        "            summed = (last * attention_mask).sum(1)\n",
        "            counts = attention_mask.sum(1).clamp(min=1e-9)\n",
        "            mean_pooled = (summed / counts).cpu().numpy()\n",
        "            embeds.append(mean_pooled)\n",
        "    return np.vstack(embeds)\n",
        "\n",
        "Xbert_train = embed_texts(X_train)\n",
        "Xbert_test = embed_texts(X_test)\n",
        "clf_bert = LogisticRegression(max_iter=1000); clf_bert.fit(Xbert_train, y_train)\n",
        "pred_bert = clf_bert.predict(Xbert_test)\n",
        "print('BERT acc', accuracy_score(y_test, pred_bert))\n",
        "print(classification_report(y_test, pred_bert))\n",
        "ConfusionMatrixDisplay(confusion_matrix(y_test, pred_bert)).plot(); plt.title('Confusion - BERT'); plt.show()\n"
      ],
      "outputs": [],
      "id": "9P8zcz5PnkLe",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽ¯ Objective 1: Sentiment Trends Across Categories"
      ],
      "metadata": {
        "id": "59-atJV8or6R"
      },
      "id": "59-atJV8or6R"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.countplot(data=df, x='category', hue='sentiment')\n",
        "plt.title(\"Sentiment Distribution Across Categories\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wNpndenrov-u"
      },
      "id": "wNpndenrov-u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽ¯ Objective 2: Keyword Frequency Analysis"
      ],
      "metadata": {
        "id": "fVd2lCxZozJF"
      },
      "id": "fVd2lCxZozJF"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from collections import Counter\n",
        "\n",
        "words = \" \".join(df['clean_text']).split()\n",
        "Counter(words).most_common(20)\n"
      ],
      "metadata": {
        "id": "4jUnrqSEoyiS"
      },
      "id": "4jUnrqSEoyiS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽ¯ Objective 3: Model Comparison â€” Which Model Performs Best?"
      ],
      "metadata": {
        "id": "VECGA3yMo5ot"
      },
      "id": "VECGA3yMo5ot"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"BoW Accuracy:\", bow_acc)\n",
        "print(\"Word2Vec Accuracy:\", w2v_acc)\n",
        "print(\"GloVe Accuracy:\", glove_acc)\n",
        "print(\"BERT Accuracy:\", bert_acc)\n"
      ],
      "metadata": {
        "id": "WRAAw_eRo-M4"
      },
      "id": "WRAAw_eRo-M4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THANKYOU"
      ],
      "metadata": {
        "id": "hlGlfsAJoVpl"
      },
      "id": "hlGlfsAJoVpl"
    }
  ]
}